{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mlrg.hmc import HMCSampler\n",
    "from rgflow import RGLayer, RGPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class GaussianModel(torch.nn.Module):\n",
    "    ''' phi4 model energy\n",
    "        E = (1/2) sum_<ij> |x_i-x_j|^2 + (r/2) sum_i |x_i|^2\n",
    "\n",
    "        Parameters:\n",
    "            r :: real - (initial) value of\n",
    "            '''\n",
    "    def __init__(self, r=0.):\n",
    "        super().__init__()\n",
    "        self.r = torch.nn.Parameter(torch.tensor(r))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'r={self.r.item()}'\n",
    "\n",
    "    def return_param(self):\n",
    "        return self.r\n",
    "\n",
    "    def clone(self):\n",
    "        mdl = type(self)()\n",
    "        mdl.load_state_dict(self.state_dict())\n",
    "        return mdl\n",
    "\n",
    "    def forward(self, x):\n",
    "        energy = 0.\n",
    "        for axis in range(2, x.dim()):\n",
    "            dx2 = (x.roll(1,axis) - x).square().sum(1)\n",
    "            energy = energy + dx2 / 2\n",
    "        x2 = x.square().sum(1)\n",
    "        energy = energy + self.r * x2 / 2\n",
    "        energy = energy.view(energy.shape[:1]+(-1,)).sum(-1)\n",
    "        return energy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([4.3420e-01, 1.6956e-01, 3.8666e-01, 2.4564e-01, 5.3521e-01, 5.6790e-02,\n",
      "        8.3578e-04, 5.8300e-02, 9.8736e-01, 1.7811e-01],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "hmc = HMCSampler(GaussianModel(r=3.), [1,1,2])\n",
    "x = hmc.sample(device, samples=10).detach()\n",
    "print(x.dim())\n",
    "print(GaussianModel(r=3.)(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True])\n",
      "tensor([[[0.4042]]])\n"
     ]
    }
   ],
   "source": [
    "x, z = RGPartition([2]).split(x)\n",
    "print(RGPartition([2]).mask)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "class RGLearner(torch.nn.Module):\n",
    "    def __init__(self, uv_model, ir_model, device, uv_shape, dim, base_dist='Normal', **kwargs):\n",
    "        super().__init__()\n",
    "        self.uv_model = uv_model.requires_grad_(False)\n",
    "        # self.ir_model = uv_model.clone().requires_grad_(True)\n",
    "        self.ir_model = ir_model.requires_grad_(True)\n",
    "        self.rglayer = RGLayer(uv_shape, device, dim, **kwargs)\n",
    "        ir_shape = self.rglayer.partitioner.out_shape\n",
    "        self.ir_sampler = HMCSampler(self.ir_model, (1, dim)+torch.Size(ir_shape))\n",
    "        self.base_dist = getattr(torch.distributions, base_dist)(0., 1.)\n",
    "        self.ir_param = self.ir_model.return_param()\n",
    "        self.uv_param = self.uv_model.return_param()\n",
    "        self.inv_K = torch.tensor([[2 + self.uv_param, -2],[-2, 2 + self.uv_param]])\n",
    "        self.K = torch.inverse(self.inv_K)\n",
    "\n",
    "    def check_ir_param(self):\n",
    "        return self.ir_param.requires_grad\n",
    "\n",
    "    def sample(self, samples, device):\n",
    "        with torch.no_grad():\n",
    "            return self.rsample(samples, device)\n",
    "\n",
    "    def rsample(self, samples, device):\n",
    "        x_ir = self.ir_sampler.sample(device, samples=samples)\n",
    "        print(x_ir.is_cuda)\n",
    "        z = self.base_dist.rsample(x_ir.shape[:2]+self.rglayer.partitioner.res_shape).to(device)\n",
    "        print(z.is_cuda)\n",
    "        x_uv, *_ = self.rglayer.decode(x_ir, z)\n",
    "        return x_uv\n",
    "\n",
    "    def loss(self, samples, device, lk=0.01, lg=0.01, mode=None, **kwargs):\n",
    "        x_ir = self.ir_sampler.sample(device, samples=samples, **kwargs)\n",
    "        z = self.base_dist.rsample(x_ir.shape[:2]+self.rglayer.partitioner.res_shape).to(device)\n",
    "        x_uv, logJ, Ek, Eg = self.rglayer.decode(x_ir, z, mode='jf_reg', **kwargs)\n",
    "        diff = self.uv_model(x_uv) - 1/2 * torch.log(1 / self.ir_param) - self.ir_model(x_ir) - logJ + 1 / 2 * torch.log(torch.det(self.K)) # The global minimum would be 0.5\n",
    "        Loss = diff + lk * Ek + lg * Eg      # original Loss\n",
    "        Loss_ = Loss.mean().detach()         # take average and detach\n",
    "        Loss = (1 + self.ir_model(x_ir).detach() + 1/2 * torch.log(1 / self.ir_param).detach() - self.ir_model(x_ir) - 1/2 * torch.log(1 / self.ir_param)) * (Loss-Loss_) # implement the reinforce algorithm. log(p(x_ir)) = -E(x_ir) + const\n",
    "        Loss, diff, Ek, Eg = [val.mean() for val in (Loss, diff, Ek, Eg)]\n",
    "        return Loss, diff, Ek, Eg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "rgl = RGLearner(GaussianModel(r=1.).to(device), GaussianModel(r=5.).to(device), device, [2], 1, hdims=[8,8], hyper_dim=16)\n",
    "optimizer = torch.optim.Adam(rgl.parameters(), lr=0.001)\n",
    "print(rgl.check_ir_param())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4495849143258965e-07 2.938091278076172 0.4170213043689728 1.0147730112075806\n",
      "2.0980834847250662e-08 2.075449228286743 0.3822191655635834 0.6212579607963562\n",
      "9.536743306171047e-08 1.749548077583313 0.386790931224823 0.36216145753860474\n",
      "7.247924571629483e-08 1.3561747074127197 0.3868293762207031 0.2308245450258255\n",
      "1.3351440841802287e-08 1.105602502822876 0.3434905409812927 0.22334060072898865\n",
      "2.574920721087892e-08 0.9526402950286865 0.3048913776874542 0.2738724648952484\n",
      "1.0490417423625331e-08 0.8986373543739319 0.2831771671772003 0.36143797636032104\n",
      "-1.907348590179936e-08 0.7896808981895447 0.34496837854385376 0.552113950252533\n",
      "1.1444091896350983e-08 0.7041557431221008 0.44465509057044983 0.6498399376869202\n",
      "-2.2888183792701966e-08 0.8220619559288025 0.5459113717079163 0.7846616506576538\n",
      "3.814697446813398e-09 0.8994033336639404 0.5892844796180725 0.8097887635231018\n",
      "3.2424928519958485e-08 0.7494833469390869 0.6217252016067505 0.9134032130241394\n",
      "2.8610228852699038e-08 0.7644792199134827 0.5773348212242126 0.9899967908859253\n",
      "1.907348590179936e-08 0.7882904410362244 0.5482765436172485 0.9539250135421753\n",
      "3.814697446813398e-09 0.7539478540420532 0.48016080260276794 1.0052626132965088\n",
      "-4.577636758540393e-08 0.6728360652923584 0.4539307653903961 0.9327715635299683\n",
      "-4.577636758540393e-08 0.6232683062553406 0.42483189702033997 0.9520186185836792\n",
      "-3.6239622858147413e-08 0.757036030292511 0.42998725175857544 0.9158041477203369\n",
      "6.67572024326546e-08 0.7574209570884705 0.41209569573402405 0.8196526169776917\n",
      "-2.8610228852699038e-08 0.608738899230957 0.3835620582103729 0.8003259301185608\n",
      "1.3351440841802287e-08 0.6523329019546509 0.34650492668151855 0.8155378103256226\n",
      "-1.5497207073167374e-08 0.6814656853675842 0.3409261107444763 0.7884171009063721\n",
      "-2.7656554379973386e-08 0.676014244556427 0.34938958287239075 0.7329864501953125\n",
      "6.389618079083448e-08 0.6084954142570496 0.34626665711402893 0.693101167678833\n",
      "-5.149841442175784e-08 0.6428878903388977 0.3711564838886261 0.7263860106468201\n",
      "-3.051757957450718e-08 0.6437035202980042 0.3681444823741913 0.7478223443031311\n",
      "2.6702881683604573e-08 0.5758039951324463 0.372923880815506 0.7397790551185608\n",
      "-1.1920929132713809e-08 0.5658491253852844 0.4123156666755676 0.7719491124153137\n",
      "9.53674295089968e-09 0.5220210552215576 0.4409949481487274 0.8103184700012207\n",
      "-6.103515914901436e-08 0.5818553566932678 0.4583694338798523 0.8266130089759827\n",
      "-4.76837147544984e-09 0.5679659843444824 0.4372861981391907 0.8118115067481995\n",
      "1.76429750808893e-08 0.5102501511573792 0.43122297525405884 0.8560883402824402\n",
      "-4.1961669694501325e-08 0.6157467365264893 0.40182259678840637 0.8728196024894714\n",
      "-9.536743617033494e-10 0.583110511302948 0.4073249399662018 0.8455201983451843\n",
      "-3.051757957450718e-08 0.5195056796073914 0.4066624939441681 0.9440330862998962\n",
      "-4.482269133632144e-08 0.5012617707252502 0.39779341220855713 0.8772305846214294\n",
      "-3.814697446813398e-09 0.5050929188728333 0.4031379222869873 0.9170987606048584\n",
      "7.05719003235572e-08 0.5295957922935486 0.40210360288619995 0.8859183192253113\n",
      "-3.33786012163273e-08 0.45935311913490295 0.3782857358455658 0.9297022819519043\n",
      "-6.484985703991697e-08 0.49056294560432434 0.393353670835495 0.9305561184883118\n",
      "1.525878978725359e-08 0.5342733263969421 0.3914960026741028 0.9458197355270386\n",
      "-2.479553273815327e-08 0.6130253076553345 0.4065975248813629 0.9828228950500488\n",
      "-3.910064805268121e-08 0.5030768513679504 0.4141658544540405 0.9562709927558899\n",
      "-4.005432074905002e-08 0.5223065614700317 0.4101342260837555 0.9504870176315308\n",
      "-2.6702881683604573e-08 0.5285494923591614 0.40054187178611755 0.9770200252532959\n",
      "1.7166136956348055e-08 0.4740860164165497 0.4198373556137085 1.0508171319961548\n",
      "7.629394893626795e-09 0.5581150054931641 0.44375649094581604 1.033204436302185\n",
      "3.051757957450718e-08 0.49022215604782104 0.42761850357055664 1.1411752700805664\n",
      "1.0490417423625331e-08 0.5434313416481018 0.4578216075897217 1.074160099029541\n",
      "-2.8610228852699038e-08 0.45489582419395447 0.46341440081596375 1.0710954666137695\n",
      "-1.907348723406699e-09 0.4730789065361023 0.45807310938835144 1.0878498554229736\n",
      "-8.249282501537891e-08 0.5544054508209229 0.4614602029323578 1.1510424613952637\n",
      "-7.629394893626795e-09 0.6033393740653992 0.4550546407699585 1.1395595073699951\n",
      "1.6212464259979242e-08 0.5466131567955017 0.45860618352890015 1.0192344188690186\n",
      "-2.0980834847250662e-08 0.6329381465911865 0.42323338985443115 1.0092257261276245\n",
      "-6.58035261835721e-08 0.4957769215106964 0.39961886405944824 0.9380945563316345\n",
      "-1.907348590179936e-08 0.5653699636459351 0.40463942289352417 1.0010395050048828\n",
      "4.482269133632144e-08 0.5389255285263062 0.38926592469215393 0.9640148878097534\n",
      "1.907348590179936e-08 0.4909079074859619 0.37012866139411926 0.9065513014793396\n",
      "-1.1444091896350983e-08 0.5829870700836182 0.3585576117038727 0.9563720226287842\n",
      "-1.4305114426349519e-08 0.5037146806716919 0.3559984564781189 0.8865940570831299\n",
      "-8.583068478174027e-09 0.5350241661071777 0.3585285246372223 0.8811383247375488\n",
      "-4.768371808516747e-10 0.538981556892395 0.35772186517715454 0.9096354246139526\n",
      "4.386901863995263e-08 0.42418187856674194 0.35694044828414917 0.8720396161079407\n",
      "1.1444091896350983e-08 0.46441102027893066 0.3448728322982788 0.9169695377349854\n",
      "1.7881394143159923e-08 0.5614943504333496 0.3739684820175171 0.8398335576057434\n",
      "4.386901863995263e-08 0.5519813299179077 0.3687852919101715 0.793019711971283\n",
      "-3.814697446813398e-09 0.5594319701194763 0.3540210425853729 0.8405224680900574\n",
      "-2.2888183792701966e-08 0.5751775503158569 0.3755134344100952 0.8338810801506042\n",
      "-1.1444091896350983e-08 0.5823904275894165 0.387342244386673 0.8183095455169678\n",
      "2.0980834847250662e-08 0.5339331030845642 0.37215420603752136 0.8206567764282227\n",
      "-2.479553273815327e-08 0.4552879333496094 0.3481077253818512 0.7846705317497253\n",
      "-9.53674295089968e-09 0.5604248642921448 0.35160908102989197 0.8051860332489014\n",
      "-4.005432074905002e-08 0.5902040600776672 0.33804625272750854 0.7570236325263977\n",
      "6.389618079083448e-08 0.6000258922576904 0.34161141514778137 0.7854110598564148\n",
      "-1.692771967043427e-08 0.49929505586624146 0.3317822217941284 0.7245867252349854\n",
      "-3.814697446813398e-09 0.5152781009674072 0.3170117139816284 0.7443532943725586\n",
      "0.0 0.5417778491973877 0.3175659775733948 0.7345788478851318\n",
      "4.5299529460862686e-08 0.5678252577781677 0.32932421565055847 0.7319642901420593\n",
      "-4.7683716530855236e-08 0.45139414072036743 0.3280085623264313 0.8265365362167358\n",
      "-1.1444091896350983e-08 0.4593064486980438 0.3264479339122772 0.7776006460189819\n",
      "2.38418573772492e-09 0.507941722869873 0.36032217741012573 0.8269217014312744\n",
      "-3.814697446813398e-09 0.5837512612342834 0.38185617327690125 0.8087465167045593\n",
      "9.536743617033494e-10 0.5106391310691833 0.3613300919532776 0.8423261642456055\n",
      "4.2915345943583816e-08 0.505945086479187 0.37097007036209106 0.8107715845108032\n",
      "-9.53674295089968e-09 0.4626976549625397 0.36166688799858093 0.8552810549736023\n",
      "1.0490417423625331e-08 0.533402681350708 0.39940035343170166 0.8268074989318848\n",
      "1.8119811429073707e-08 0.5758000016212463 0.3985862731933594 0.8258417248725891\n",
      "-2.4318694613612024e-08 0.5155444145202637 0.3734242022037506 0.8817691206932068\n",
      "-2.479553273815327e-08 0.46033716201782227 0.3664257228374481 0.851351797580719\n",
      "-2.38418573772492e-09 0.5189230442047119 0.3527853488922119 0.8937047719955444\n",
      "1.7166136956348055e-08 0.5256931781768799 0.35172948241233826 0.771337628364563\n",
      "1.525878978725359e-08 0.46235528588294983 0.33908554911613464 0.7879900932312012\n",
      "4.959106547630654e-08 0.4675229787826538 0.3281763195991516 0.7803927659988403\n",
      "-5.7220457705398076e-08 0.49961134791374207 0.3475862443447113 0.7394596338272095\n",
      "-5.364417887676609e-08 0.46679720282554626 0.34393611550331116 0.724087655544281\n",
      "-1.907348723406699e-09 0.47101202607154846 0.33045241236686707 0.7818936705589294\n",
      "2.479553273815327e-08 0.5468281507492065 0.3429461419582367 0.7696459889411926\n",
      "3.051757957450718e-08 0.453695684671402 0.3577670454978943 0.7804493308067322\n",
      "1.907348590179936e-08 0.47354134917259216 0.3564489781856537 0.7864497303962708\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        loss, *rest = rgl.loss(1000, device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'{loss.item()} '+' '.join(f'{r.item()}' for r in rest))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "GaussianModel(r=4.96737813949585)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgl.ir_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
